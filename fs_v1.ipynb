{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     site_id  FuelId transaction_date_time   price\n",
      "10  61401008     2.0   2024-10-03T12:30:00  1979.0\n",
      "11  61401008     5.0   2024-10-03T12:30:00  2129.0\n",
      "12  61401008     8.0   2024-10-03T12:30:00  2209.0\n",
      "13  61401008    12.0   2024-10-03T12:30:00  1959.0\n",
      "14  61401008    14.0   2024-10-03T12:30:00  1839.0\n",
      "    site_id            address        station_name postcode   latitude   \n",
      "0  61290151     61 Burrowes St       Liberty Surat     4417 -27.151627  \\\n",
      "1  61290151     61 Burrowes St       Liberty Surat     4417 -27.151627   \n",
      "2  61290151     61 Burrowes St       Liberty Surat     4417 -27.151627   \n",
      "3  61291313  126 Barwon Street  Lowes Mungindi Opt     4497 -28.973667   \n",
      "4  61291313  126 Barwon Street  Lowes Mungindi Opt     4497 -28.973667   \n",
      "\n",
      "    longitude                        gp_id brand_name   \n",
      "0  149.067712  ChIJhbUB8XJVumsR1WCVwJFOMiY    Liberty  \\\n",
      "1  149.067712  ChIJhbUB8XJVumsR1WCVwJFOMiY    Liberty   \n",
      "2  149.067712  ChIJhbUB8XJVumsR1WCVwJFOMiY    Liberty   \n",
      "3  148.983999  ChIJWyNloETOpWsR2iAu7eiMx30         BP   \n",
      "4  148.983999  ChIJWyNloETOpWsR2iAu7eiMx30         BP   \n",
      "\n",
      "     transaction_date_time   price            fuel_name  FuelId  \n",
      "0  2024-06-02T23:56:20.107  1899.0             Unleaded     2.0  \n",
      "1   2024-08-23T23:49:59.33  1899.0               Diesel     3.0  \n",
      "2  2024-06-02T23:56:20.107  2099.0  Premium Unleaded 98     8.0  \n",
      "3   2024-10-01T22:14:33.93  1830.0             Unleaded     2.0  \n",
      "4   2024-09-18T22:00:58.63  1820.0               Diesel     3.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set your API token\n",
    "token = \"5067f5e2-7e7f-49a7-bf4e-69b069e204c4\"  # Replace with your actual token\n",
    "\n",
    "# Set the headers for the request\n",
    "headers = {\n",
    "    \"Authorization\": f\"FPDAPI SubscriberToken={token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Function to fetch fuel data (as in your original code)\n",
    "def fetch_fuel_data():\n",
    "    # Fetch Fuel Types, Brands, Site Details, Site Prices as in your code\n",
    "    # ...\n",
    "\n",
    "    # Step 1: Get Fuel Types\n",
    "    url_fuel_types = \"https://fppdirectapi-prod.fuelpricesqld.com.au/Subscriber/GetCountryFuelTypes\"\n",
    "    response_fuel_types = requests.get(url_fuel_types, headers=headers, params={\"countryId\": \"21\"})\n",
    "    df_fuel_types = pd.DataFrame()\n",
    "    if response_fuel_types.status_code == 200:\n",
    "        fuel_types_data = response_fuel_types.json()['Fuels']\n",
    "        df_fuel_types = pd.json_normalize(fuel_types_data)\n",
    "\n",
    "    # Step 2: Get Brands\n",
    "    url_brands = \"https://fppdirectapi-prod.fuelpricesqld.com.au/Subscriber/GetCountryBrands\"\n",
    "    response_brands = requests.get(url_brands, headers=headers, params={\"countryId\": \"21\"})\n",
    "    df_brands = pd.DataFrame()\n",
    "    if response_brands.status_code == 200:\n",
    "        brands_data = response_brands.json()['Brands']\n",
    "        df_brands = pd.json_normalize(brands_data)\n",
    "\n",
    "    # Step 3: Get Site Details\n",
    "    url_site_details = \"https://fppdirectapi-prod.fuelpricesqld.com.au/Subscriber/GetFullSiteDetails\"\n",
    "    response_sites = requests.get(url_site_details, headers=headers, params={\"countryId\": \"21\", \"GeoRegionLevel\": \"3\", \"GeoRegionId\": \"1\"})\n",
    "    df_sites_all = pd.DataFrame()\n",
    "    if response_sites.status_code == 200:\n",
    "        sites_data = response_sites.json()['S']  # Assuming the key is 'Sites'\n",
    "        df_sites_all = pd.json_normalize(sites_data)\n",
    "        df_sites_all.rename(columns={\n",
    "            'S': 'Site ID',\n",
    "            'N': 'Name',\n",
    "            'A': 'Address',\n",
    "            'B': 'Brand ID',\n",
    "            'P': 'Postcode',\n",
    "            'G1': 'Geographic Region Level 1',\n",
    "            'G2': 'Geographic Region Level 2',\n",
    "            'G3': 'Geographic Region Level 3',\n",
    "            'G4': 'Geographic Region Level 4',\n",
    "            'G5': 'Geographic Region Level 5',\n",
    "            'Lat': 'Latitude',\n",
    "            'Lng': 'Longitude',\n",
    "            'M': 'Last Modified',\n",
    "            'GPI': 'Google Place ID'\n",
    "        }, inplace=True)\n",
    "\n",
    "    # Step 4: Get Site Prices\n",
    "    url_site_prices = \"https://fppdirectapi-prod.fuelpricesqld.com.au/Price/GetSitesPrices\"\n",
    "    response_prices = requests.get(url_site_prices, headers=headers, params={\"countryId\": \"21\", \"geoRegionLevel\": \"3\", \"geoRegionId\": \"1\"})\n",
    "    df_fuel_prices = pd.DataFrame()\n",
    "    if response_prices.status_code == 200:\n",
    "        fuel_prices_data = response_prices.json()['SitePrices']\n",
    "        df_fuel_prices = pd.json_normalize(fuel_prices_data)\n",
    "\n",
    "    # Step 5: Merge DataFrames\n",
    "    # Merge site details with brands using 'Brand ID'\n",
    "    merged_df = pd.merge(df_sites_all, df_brands, left_on='Brand ID', right_on='BrandId', how='left')\n",
    "\n",
    "    # Merge fuel prices with sites using 'Site ID'\n",
    "    merged_df = pd.merge(merged_df, df_fuel_prices, left_on='Site ID', right_on='SiteId', how='left')\n",
    "\n",
    "    # Merge fuel types with prices using 'FuelId'\n",
    "    merged_df = pd.merge(merged_df, df_fuel_types, left_on='FuelId', right_on='FuelId', how='left')\n",
    "\n",
    "    # Select and rename the desired columns\n",
    "    final_df = merged_df[[\n",
    "        'Site ID', 'Address', 'Name_x', 'Postcode', 'Latitude', \n",
    "        'Longitude', 'Google Place ID', 'Name_y', 'TransactionDateUtc', \n",
    "        'Price', 'Name', 'FuelId'\n",
    "    ]].rename(columns={\n",
    "        'Site ID': 'site_id',\n",
    "        'Address': 'address',\n",
    "        'Name_x': 'station_name',\n",
    "        'Postcode': 'postcode',\n",
    "        'Latitude': 'latitude',\n",
    "        'Longitude': 'longitude',\n",
    "        'Google Place ID': 'gp_id',\n",
    "        'Name_y': 'brand_name',\n",
    "        'TransactionDateUtc': 'transaction_date_time',\n",
    "        'Price': 'price',\n",
    "        'Name': 'fuel_name'\n",
    "    })\n",
    "\n",
    "\n",
    "    # Merge data as in your original code\n",
    "    # final_df = merged_df[...]  # your merged dataframe\n",
    "    return final_df\n",
    "\n",
    "# Function to compare and get new/updated data\n",
    "def get_new_data(new_data, old_data):\n",
    "\n",
    "    # Ensure postcodes are strings in both DataFrames\n",
    "    new_data['postcode'] = new_data['postcode'].astype(str)\n",
    "    old_data['postcode'] = old_data['postcode'].astype(str)\n",
    "\n",
    "    # Merge new and old data based on site_id and FuelId\n",
    "    merged = pd.merge(new_data, old_data, how='left', \n",
    "                      on=['site_id', 'FuelId'], \n",
    "                      suffixes=('_new', '_old'), \n",
    "                      indicator=True)\n",
    "    \n",
    "    # Find rows where transaction_date_time or price have changed\n",
    "    diff = merged[\n",
    "        (merged['_merge'] == 'left_only') |  # New entries\n",
    "        (merged['transaction_date_time_new'] != merged['transaction_date_time_old']) |  # Date changed\n",
    "        (merged['price_new'] != merged['price_old'])  # Price changed\n",
    "    ]\n",
    "    \n",
    "    # Keep only the relevant columns (site_id, FuelId, and the changed values)\n",
    "    diff = diff[['site_id', 'FuelId', 'transaction_date_time_new', 'price_new']].rename(columns={\n",
    "        'transaction_date_time_new': 'transaction_date_time',\n",
    "        'price_new': 'price'\n",
    "    })\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "\n",
    "# File path\n",
    "file_path = 'fuel_data_oct.csv'\n",
    "\n",
    "# Step 1: Fetch new data\n",
    "new_df = fetch_fuel_data()\n",
    "\n",
    "# Step 2: Check if the file already exists\n",
    "if os.path.exists(file_path):\n",
    "    # Load existing data\n",
    "    old_df = pd.read_csv(file_path)\n",
    "\n",
    "    # Step 3: Compare and get the new/updated data\n",
    "    diff_df = get_new_data(new_df, old_df)\n",
    "    \n",
    "    if not diff_df.empty:\n",
    "        # Step 4: Append only new/updated data to CSV\n",
    "        #diff_df.to_csv(file_path, mode='a', header=False, index=False)\n",
    "        #print(f\"{len(diff_df)} new/updated rows added.\")\n",
    "        print(diff_df.head(5))\n",
    "    else:\n",
    "        print(\"No updates found.\")\n",
    "else:\n",
    "    # Step 4: Save the new data to CSV if file doesn't exist\n",
    "    #new_df.to_csv(file_path, index=False)\n",
    "    print(f\"{len(new_df)} rows saved to new file.\")\n",
    "\n",
    "# Step 5: Display new data or message\n",
    "print(new_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
